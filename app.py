import streamlit as st
from langchain_community.chat_models import ChatTongyi
from langchain.agents import create_agent
from langchain_core.messages import HumanMessage, AIMessage

# å¤ç”¨æˆ‘ä»¬ä¹‹å‰è§£è€¦å¥½çš„æ¨¡å—
from config import GRAPH_NAME
from tools import execute_cypher_query

# è¿è¡Œæ–¹å¼ï¼š
# streamlit run app.py
# streamlit run app.py --server.address 0.0.0.0

# ================== 1. é¡µé¢é…ç½® ==================
st.set_page_config(
    page_title="å›¾æ•°æ®åº“æ™ºèƒ½åŠ©æ‰‹",
    page_icon="ğŸ¤–",
    layout="centered"
)

st.title(f"ğŸ¤– åœ°ç¾æ•°æ®æ™ºèƒ½é—®ç­”åŠ©æ‰‹")
st.caption(f"å½“å‰è¿æ¥å›¾è°±: `{GRAPH_NAME}`")

# ================== 2. åˆå§‹åŒ– Agent (å¸¦ç¼“å­˜) ==================
# ä½¿ç”¨ cache_resource è£…é¥°å™¨ï¼Œé˜²æ­¢æ¯æ¬¡ç‚¹å‡»æŒ‰é’®éƒ½é‡æ–°åŠ è½½æ¨¡å‹
@st.cache_resource
def get_agent():
    llm = ChatTongyi(model_name="qwen-max", temperature=0)
    tools = [execute_cypher_query]
    
    system_prompt = f"""
ä½ æ˜¯ä¸€ä¸ª Apache AGE å›¾æ•°æ®åº“ä¸“å®¶ã€‚
å›¾è°± Schema: 
-å›¾åç§° {GRAPH_NAME}
-èŠ‚ç‚¹æ ‡ç­¾ :æ ¸æŸ¥äººã€æ ¸æŸ¥å•ä½ã€é˜²å¾¡åŒºã€æ‰¿ç¾ä½“
-å…³ç³»ç±»å‹ :éš¶å±ã€æ ¸æŸ¥ã€é˜²å¾¡åŒºæ‰¿ç¾ä½“å…³ç³»

- **ã€é‡è¦å±æ€§è§„åˆ™ã€‘**: 
1. **åç§°/åå­—æŸ¥è¯¢**: ç”¨æˆ·è¾“å…¥åç§°ï¼ˆå¦‚å¼ ä¸‰ã€AåŒºï¼‰æ—¶ï¼Œå±æ€§é”®**å›ºå®šä¸º 'å§“å'**ã€‚
   - ç¤ºä¾‹: "æ‰¾å¼ ä¸‰" -> MATCH (n {{å§“å: 'å¼ ä¸‰'}})
2. **ID æŸ¥è¯¢**: ç”¨æˆ·æä¾› "ID" æˆ– "ç¼–å·" æ—¶ï¼Œå¿…é¡»æ ¹æ®èŠ‚ç‚¹ç±»å‹é€‰æ‹©å¯¹åº”çš„å”¯ä¸€æ ‡è¯†å­—æ®µï¼š
   - é˜²å¾¡åŒº -> å±æ€§é”®ä¸º 'é˜²å¾¡åŒºå”¯ä¸€æ ‡è¯†'
   - æ‰¿ç¾ä½“ -> å±æ€§é”®ä¸º 'æ‰¿ç¾ä½“å”¯ä¸€æ ‡è¯†'
   - æ ¸æŸ¥äºº -> å±æ€§é”®ä¸º 'å§“å' 
   - ç¤ºä¾‹: "IDä¸º123çš„é˜²å¾¡åŒº" -> MATCH (n:é˜²å¾¡åŒº {{é˜²å¾¡åŒºå”¯ä¸€æ ‡è¯†: '123'}})

ã€æ ¸å¿ƒè§„åˆ™ã€‘
1. åªç”Ÿæˆ MATCH/RETURN è¯­å¥ï¼Œä¸¥ç¦ç”Ÿæˆ SQLã€‚
2. **ã€å¼ºåˆ¶ã€‘å˜é‡ç»‘å®šè§„åˆ™**:
   åœ¨ MATCH å­å¥ä¸­ï¼Œ**å¿…é¡»**ä¸ºå…³ç³»æŒ‡å®šå˜é‡åï¼ˆé€šå¸¸ç”¨ `r`ï¼‰ï¼Œ**ä¸¥ç¦**ä½¿ç”¨åŒ¿åå…³ç³»ï¼
   - âŒ é”™è¯¯å†™æ³•: `MATCH (a)-[:æ ¸æŸ¥]->(b)` (ä¼šå¯¼è‡´åé¢æ— æ³•å¼•ç”¨ r)
   - âœ… æ­£ç¡®å†™æ³•: `MATCH (a)-[r:æ ¸æŸ¥]->(b)` (å¿…é¡»æ˜¾å¼å®šä¹‰ r)

3. **ã€å…³é”®ã€‘è¿”å›æ ¼å¼è§„èŒƒ**ï¼š
   - **æŸ¥èŠ‚ç‚¹æ—¶**ï¼šè¿”å›èŠ‚ç‚¹æœ¬èº«ã€‚MATCH (n:æ ¸æŸ¥äºº) RETURN {{node: n}}
   - **æŸ¥å…³ç³»æ—¶**ï¼šå¿…é¡»åŒæ—¶è¿”å›ã€èµ·ç‚¹ã€å…³ç³»ã€ç»ˆç‚¹ã€‘ç»„æˆçš„å®Œæ•´ä¸Šä¸‹æ–‡ã€‚
     âœ… æ­£ç¡®ï¼šMATCH (a)-[r:éš¶å±]->(b) RETURN {{source: a, rel: r, target: b}}
   
4. å¿…é¡»å°†æ‰€æœ‰è¿”å›å­—æ®µå°è£…åœ¨ä¸€ä¸ª Map å¯¹è±¡ä¸­ã€‚
"""
    
    return create_agent(model=llm, tools=tools, system_prompt=system_prompt)

agent = get_agent()

# ================== 3. ç®¡ç†èŠå¤©è®°å½• ==================
# å¦‚æœ session_state ä¸­æ²¡æœ‰ messagesï¼Œåˆå§‹åŒ–ä¸€ä¸ªç©ºçš„
if "messages" not in st.session_state:
    st.session_state.messages = []

# åœ¨ç•Œé¢ä¸Šé‡ç»˜å†å²æ¶ˆæ¯
for msg in st.session_state.messages:
    # åŒºåˆ†ç”¨æˆ·æ¶ˆæ¯å’Œ AI æ¶ˆæ¯çš„å¤´åƒ
    avatar = "ğŸ§‘â€ğŸ’»" if isinstance(msg, HumanMessage) else "ğŸ¤–"
    with st.chat_message(msg.type, avatar=avatar):
        st.markdown(msg.content)

# ================== 4. å¤„ç†ç”¨æˆ·è¾“å…¥ ==================
if prompt := st.chat_input("è¯·è¾“å…¥ä½ æƒ³æŸ¥è¯¢çš„å†…å®¹ï¼ˆä¾‹å¦‚ï¼šæœ‰å“ªäº›æ ¸æŸ¥äººï¼Ÿï¼‰..."):
    # 1. æ˜¾ç¤ºç”¨æˆ·è¾“å…¥
    with st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»"):
        st.markdown(prompt)
    # å°†ç”¨æˆ·æ¶ˆæ¯åŠ å…¥å†å²
    st.session_state.messages.append(HumanMessage(content=prompt))

    # 2. è°ƒç”¨ Agent
    with st.chat_message("assistant", avatar="ğŸ¤–"):
        message_placeholder = st.empty()
        message_placeholder.markdown("ğŸ§  æ­£åœ¨æ€è€ƒå¹¶æŸ¥è¯¢æ•°æ®åº“...")
        
        try:
            # æ„é€  LangGraph éœ€è¦çš„è¾“å…¥æ ¼å¼
            # æ³¨æ„ï¼šæˆ‘ä»¬éœ€è¦æŠŠæ•´ä¸ªå†å²è®°å½•ä¼ ç»™ Agentï¼Œè¿™æ ·å®ƒæ‰æœ‰ä¸Šä¸‹æ–‡è®°å¿†
            # ä½†ä¸ºäº†èŠ‚çœ Tokenï¼Œç®€å•åœºæ™¯ä¹Ÿå¯ä»¥åªä¼ æœ€æ–°çš„ä¸€æ¡
            
            # è¿™é‡Œæˆ‘ä»¬åªä¼ æœ€æ–°é—®é¢˜ï¼Œé¿å…æŠŠæ—§çš„ Tool è°ƒç”¨è®°å½•æä¹±
            input_data = {
                "messages": [
                    {"role": "user", "content": prompt}
                ]
            }

            # æŠŠ session_state é‡Œçš„æ‰€æœ‰æ¶ˆæ¯ä¼ ç»™ Agent
            # full_history = st.session_state.messages
            # input_data = {
            #     "messages": full_history
            # }

            # åªå–æœ€å 6 æ¡æ¶ˆæ¯ä½œä¸ºä¸Šä¸‹æ–‡
            # recent_history = st.session_state.messages[-6:] 
            # input_data = {
            #     "messages": recent_history
            # }
            
            # æ‰§è¡Œè°ƒç”¨
            result = agent.invoke(input_data)
            
            # è·å–æœ€ç»ˆå›å¤
            final_response = result['messages'][-1].content
            
            # æ˜¾ç¤ºç»“æœ
            message_placeholder.markdown(final_response)
            
            # å°† AI å›å¤åŠ å…¥å†å²
            st.session_state.messages.append(AIMessage(content=final_response))
            
        except Exception as e:
            message_placeholder.error(f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}")