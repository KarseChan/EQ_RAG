# app.py
import streamlit as st
import pandas as pd
import json
from langchain_community.chat_models import ChatTongyi
from langchain.agents import create_agent
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage
from streamlit_agraph import agraph, Node, Edge, Config

# --- å¯¼å…¥è§£è€¦çš„æ¨¡å— ---
from config import GRAPH_NAME, LLM_MODEL_NAME
from tools import execute_cypher_query, generate_graph_from_data, search_knowledge_base
from prompts import get_system_prompt       
from memory import build_chat_context       

# ================== 1. é¡µé¢é…ç½® ==================
st.set_page_config(page_title="åœ°ç¾æ•°æ®åŠ©æ‰‹", page_icon="ğŸŒ", layout="centered")

# ================== 2. ä¾§è¾¹æ é…ç½® ==================
with st.sidebar:
    st.header("âš™ï¸ è®¾ç½®é¢æ¿")
    
    # --- è®°å¿†ç­–ç•¥æ§åˆ¶ ---
    st.subheader("ğŸ§  è®°å¿†è®¾ç½®")
    memory_type = st.radio(
        "è®°å¿†æ¨¡å¼",
        ("æ»‘åŠ¨çª—å£ (æ¨è)", "å…¨é‡è®°å¿† (Tokenæ¶ˆè€—å¤§)", "ä¸è®°å¿† (å•è½®å¯¹è¯)"),
        index=0
    )
    
    # æ˜ å°„ UI é€‰é¡¹åˆ°ä»£ç ç­–ç•¥ key
    strategy_map = {
        "æ»‘åŠ¨çª—å£ (æ¨è)": "window",
        "å…¨é‡è®°å¿† (Tokenæ¶ˆè€—å¤§)": "full",
        "ä¸è®°å¿† (å•è½®å¯¹è¯)": "none"
    }
    selected_strategy = strategy_map[memory_type]
    
    # åªæœ‰é€‰æ»‘åŠ¨çª—å£æ—¶æ‰æ˜¾ç¤ºæ»‘å—
    window_k = 6
    if selected_strategy == "window":
        window_k = st.slider("è®°å¿†è½®æ•° (æ¶ˆæ¯æ¡æ•°)", min_value=2, max_value=20, value=6, step=2)

    st.divider()
    
    # --- å¸¸ç”¨åŠŸèƒ½ ---
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯å†å²", width='stretch'):
        st.session_state.messages = []
        st.rerun()

    st.markdown("### ğŸ’¡ å¿«æ·æé—®")
    example_questions = ["æœ±ç‚³æ¹–è´Ÿè´£çš„é˜²å¾¡åŒºä¸­é¢ç§¯æœ€å¤§çš„æ˜¯å“ªä¸ªï¼Ÿ",
                         "å“ªäº›é˜²å¾¡åŒºé£é™©ç­‰çº§æ˜¯ä¸­çº§ï¼Ÿ",
                         "æ‰¿ç¾ä½“é‡Œå¨èƒè´¢äº§æœ€å¤šçš„å‰5ä¸ªï¼Ÿ",
                         "å“ªäº›é˜²å¾¡åŒºæ˜¯å¡åº¦è¾ƒç¼“",
                         "äººå·¥åˆ‡å¡é«˜2ç±³çš„é˜²å¾¡åŒºå¯¹åº”çš„è´Ÿè´£äººæ˜¯è°"]
    for q in example_questions:
        if st.button(q, width='stretch'):
            st.session_state.current_prompt = q

# ================== 3. ä¸»ç•Œé¢ & Agent åˆå§‹åŒ– ==================
st.title(f"ğŸŒ åœ°ç¾æ•°æ®æ™ºèƒ½åŠ©æ‰‹")
st.caption(f"å½“å‰è¿æ¥å›¾è°±: `{GRAPH_NAME}` | è®°å¿†æ¨¡å¼: `{memory_type}`")

@st.cache_resource
def get_agent_instance():
    # åˆå§‹åŒ–æ¨¡å‹
    llm = ChatTongyi(model_name=LLM_MODEL_NAME, temperature=0)
    tools = [execute_cypher_query, search_knowledge_base]
    
    # ä» prompts.py è·å–æç¤ºè¯
    system_prompt = get_system_prompt()
    print(f"[app] æç¤ºè¯ï¼š {system_prompt}")
    
    return create_agent(model=llm, tools=tools, system_prompt=system_prompt)

agent = get_agent_instance()

# ================== 4. æ¸²æŸ“å†å²ä¸å¤„ç†è¾“å…¥ ==================
if "messages" not in st.session_state:
    st.session_state.messages = []

# æ¸²æŸ“å†å²
for msg in st.session_state.messages:
    avatar = "ğŸ§‘â€ğŸ’»" if isinstance(msg, HumanMessage) else "ğŸ¤–"
    with st.chat_message(msg.type, avatar=avatar):
        st.markdown(msg.content)

# 2. è·å–è¾“å…¥ï¼ˆå…³é”®ä¿®æ”¹ï¼šè®© chat_input å§‹ç»ˆæ¸²æŸ“ï¼‰
chat_input_text = st.chat_input("è¯·è¾“å…¥æŸ¥è¯¢å†…å®¹...")
button_input_text = st.session_state.get("current_prompt", None)

# 3. å†³å®šæœ€ç»ˆä½¿ç”¨å“ªä¸ªè¾“å…¥ (ä¼˜å…ˆå“åº”æŒ‰é’®ï¼Œå…¶æ¬¡å“åº”è¾“å…¥æ¡†)
user_input = None

if button_input_text:
    user_input = button_input_text
    # æ¶ˆè´¹æ‰è¿™ä¸ªçŠ¶æ€ï¼Œé˜²æ­¢åˆ·æ–°åæ­»å¾ªç¯
    del st.session_state["current_prompt"]
elif chat_input_text:
    user_input = chat_input_text

if user_input:
    if "current_prompt" in st.session_state: del st.session_state["current_prompt"]

    # 1. UI æ˜¾ç¤ºç”¨æˆ·é—®é¢˜
    with st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»"):
        st.markdown(user_input)

    # 2. è°ƒç”¨ Agent
    with st.chat_message("assistant", avatar="ğŸ¤–"):
        msg_placeholder = st.empty()
        status = st.status("ğŸ§  æ€è€ƒä¸­...", expanded=True)
        
        try:
            status.write(f"æ­£åœ¨æ„å»ºä¸Šä¸‹æ–‡ (ç­–ç•¥: {selected_strategy})...")
            
            # [æ–°] è°ƒç”¨ memory.py æ„å»ºä¸Šä¸‹æ–‡
            input_payload = build_chat_context(
                current_prompt=user_input,
                history=st.session_state.messages,
                strategy=selected_strategy,
                k=window_k
            )

            # 
            # input_data = {
            #     "messages": [
            #         {"role": "user", "content": user_input}
            #     ]
            # }
            
            # Agent æ‰§è¡Œ
            result = agent.invoke(input_payload)
            # result = agent.invoke(input_data)

            final_response = result['messages'][-1].content

            # --- æ•°æ®æå–é€»è¾‘ ---
            raw_data_json = None # ä¿å­˜åŸå§‹ JSON åˆ—è¡¨
            raw_data_df = None   # ä¿å­˜è¡¨æ ¼ DF

            print(f"[App] Agentå›å¤çš„ä¿¡æ¯ï¼š{result['messages']}")

            # æå–æ•°æ®
            raw_data_list = []
            for msg in result['messages']:
                if isinstance(msg, ToolMessage):
                    try:
                        # 1. è§£æ JSON
                        data = json.loads(msg.content)
                        
                        # 2. æƒ…å†µ A: å›¾è°±æŸ¥è¯¢ (ç›´æ¥è¿”å› List)
                        if isinstance(data, list):
                            raw_data_list.extend(data) # å»ºè®®ç”¨ extend è€Œä¸æ˜¯ =ï¼Œé˜²æ­¢è¢«è¦†ç›–
                        
                        # 3. æƒ…å†µ B: è¯­ä¹‰æ£€ç´¢ (è¿”å› Dictï¼Œæ•°æ®åœ¨ 'search_results' é‡Œ)
                        elif isinstance(data, dict):
                            # ä¼˜å…ˆæ‰¾ search_results
                            if 'search_results' in data and isinstance(data['search_results'], list):
                                raw_data_list.extend(data['search_results'])
                            # å…¼å®¹æ€§å…œåº•: å¦‚æœä»¥åæœ‰å…¶ä»–è¿”å› dict çš„å·¥å…·ï¼Œä¹Ÿå¯ä»¥åœ¨è¿™é‡Œå¤„ç†
                            
                    except Exception as e:
                        print(f"æ•°æ®è§£æå¤±è´¥: {e}")
                        pass
            
            # === 1. å±•ç¤ºå›¾è°± (æ–°å¢åŠŸèƒ½) ===
            # if raw_data_jPson is not None:
            #     # åªæœ‰å½“æ•°æ®é‡ŒåŒ…å« source/target ç»“æ„æ—¶æ‰ç”»å›¾ï¼Œé˜²æ­¢çº¯èŠ‚ç‚¹æŸ¥è¯¢æŠ¥é”™
            #     # ç®€å•çš„åˆ¤æ–­é€»è¾‘ï¼šçœ‹ç¬¬ä¸€æ¡æ•°æ®æœ‰æ²¡æœ‰ 'source' é”®
            #     if "source" in raw_data_json[0] and "target" in raw_data_json[0]:
            #         with st.expander("ğŸ•¸ï¸ çŸ¥è¯†å›¾è°±å¯è§†åŒ–", expanded=True):
            #             nodes, edges, config = generate_graph_from_data(raw_data_json)
            #             # æ¸²æŸ“å›¾è°±
            #             agraph(nodes=nodes, edges=edges, config=config)
            
            # === 2. å±•ç¤ºè¡¨æ ¼ (åŸæœ‰åŠŸèƒ½) ===
            print(f'å±•ç¤ºè¡¨æ ¼æ•°æ®: {raw_data_df}')
            # æ˜¾ç¤ºè¡¨æ ¼
            if raw_data_list:
                df = pd.json_normalize(raw_data_list)
                st.dataframe(df)

            status.update(label="âœ… å®Œæˆ", state="complete", expanded=False)
            
            
            # æ˜¾ç¤ºæ–‡æœ¬å›å¤
            msg_placeholder.markdown(final_response)
            
            # 3. æ›´æ–°å†å² (æˆåŠŸåæ‰å­˜å…¥)
            # st.session_state.messages.append(HumanMessage(content=user_input))
            # st.session_state.messages.append(AIMessage(content=final_response))
            
        except Exception as e:
            status.update(label="âŒ å‡ºé”™", state="error")
            msg_placeholder.error(f"Error: {str(e)}")