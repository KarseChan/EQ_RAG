import os
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import psycopg2
from sentence_transformers import SentenceTransformer
from config import DB_CONFIG, GRAPH_NAME, ORIGIN_NAME

# å¤ç”¨ä½ è„šæœ¬é‡Œçš„é…ç½®
MODEL_NAME = 'BAAI/bge-small-zh-v1.5'
SEARCH_COLUMN = "æ ¸æŸ¥æè¿°"

# === 1. å®šä¹‰å¤šè¡¨é…ç½® (æ ¸å¿ƒä¿®æ”¹) ===
# è¿™é‡Œå®šä¹‰ä½ æƒ³è®© Agent æ£€ç´¢çš„æ‰€æœ‰ä¸šåŠ¡è¡¨
VECTOR_TABLES_CONFIG = [
    {
        "name": "é˜²å¾¡åŒº",               # ä¸šåŠ¡åç§°
        "source_table": "é˜²å¾¡åŒº",       # åŸå§‹è¡¨å
        "target_table": "é˜²å¾¡åŒº_embeddings", # å‘é‡è¡¨å
        "search_column": "æ ¸æŸ¥æè¿°",    # ç”¨äºå‘é‡åŒ–çš„æ–‡æœ¬åˆ—
        "id_column": "é˜²å¾¡åŒºç¼–å·",       # ä¸šåŠ¡ä¸»é”®
        "risk_level": "é£é™©ç­‰çº§",
        "area": "é¢ç§¯"
    }
    # {
    #     "name": "æ‰¿ç¾ä½“",               # ä¸šåŠ¡åç§°
    #     "source_table": "æ‰¿ç¾ä½“",       # åŸå§‹è¡¨å
    #     "target_table": "æ‰¿ç¾ä½“_embeddings", # å‘é‡è¡¨å
    #     "search_column": "åœ°ç†ä½ç½®",    # ç”¨äºå‘é‡åŒ–çš„æ–‡æœ¬åˆ—
    #     "id_column": "æ‰¿ç¾ä½“ç¼–å·",       # ä¸šåŠ¡ä¸»é”®
    # }
]

def sync_data_to_pgvector():
    print("1. åŠ è½½æœ¬åœ° Embedding æ¨¡å‹...")
    model = SentenceTransformer(MODEL_NAME)
    
    print("2. è¿æ¥æ•°æ®åº“...")
    conn = psycopg2.connect(**DB_CONFIG)
    cursor = conn.cursor()
    
    # ç¡®ä¿å‘é‡æ’ä»¶å¼€å¯
    cursor.execute("CREATE EXTENSION IF NOT EXISTS vector;")
    
    # åˆ›å»ºå­˜å‚¨å‘é‡çš„è¡¨ (å¦‚æœä¸å­˜åœ¨)
    cursor.execute(f'CREATE SCHEMA IF NOT EXISTS "{ORIGIN_NAME}";') # ç¡®ä¿ Schema å­˜åœ¨



    # === 2. å¾ªç¯å¤„ç†æ¯ä¸ªé…ç½® ===
    for config in VECTOR_TABLES_CONFIG:
        src_table = config["source_table"]
        tgt_table = config["target_table"]
        col_name = config["search_column"]
        id_col = config["id_column"]
        
        print(f"\nğŸš€ æ­£åœ¨å¤„ç†ä¸šåŠ¡: {config['name']} ...")

        # A. åŠ¨æ€å»ºè¡¨
        cursor.execute(f"""
            CREATE TABLE IF NOT EXISTS "{ORIGIN_NAME}"."{tgt_table}" (
                id SERIAL PRIMARY KEY,
                node_id VARCHAR(50),      
                content TEXT,             
                full_metadata JSONB,      
                embedding vector(512)     
            );
            CREATE INDEX IF NOT EXISTS "idx_{tgt_table}" 
            ON "{ORIGIN_NAME}"."{tgt_table}" USING hnsw (embedding vector_cosine_ops);
        """)
        
        # B. åŠ¨æ€è¯»å–
        print(f"   è¯»å–æºè¡¨: {src_table}...")
        try:
            cursor.execute(f'SELECT * FROM "{ORIGIN_NAME}"."{src_table}" WHERE "{col_name}" IS NOT NULL')
            columns = [desc[0] for desc in cursor.description]
            rows = cursor.fetchall()
        except Exception as e:
            print(f"   âš ï¸ è·³è¿‡: è¡¨ {src_table} è¯»å–å¤±è´¥æˆ–ä¸å­˜åœ¨ ({e})")
            continue

        if not rows:
            print("   âš ï¸ è·³è¿‡: æ— æ•°æ®")
            continue

        # C. æ‰¹é‡å‘é‡åŒ–
        data_to_insert = []
        print(f"   æ­£åœ¨å‘é‡åŒ– {len(rows)} æ¡æ•°æ®...")
        
        for row in rows:
            row_dict = dict(zip(columns, row))
            text_content = row_dict.get(col_name, "")
            
            # åŠ¨æ€è·å– ID
            node_id = str(row_dict.get(id_col, 'unknown'))
            
            vector = model.encode(text_content).tolist()
            
            import json
            data_to_insert.append((
                node_id, 
                text_content, 
                json.dumps(row_dict, default=str), 
                vector
            ))

        # D. å†™å…¥ (å…ˆæ¸…ç©ºæ—§æ•°æ®ï¼Œé˜²æ­¢é‡å¤å åŠ ï¼Œæ ¹æ®éœ€æ±‚å¯é€‰)
        cursor.execute(f'TRUNCATE TABLE "{ORIGIN_NAME}"."{tgt_table}"')
        
        insert_query = f"""
            INSERT INTO "{ORIGIN_NAME}"."{tgt_table}" 
            (node_id, content, full_metadata, embedding) 
            VALUES (%s, %s, %s, %s)
        """
        cursor.executemany(insert_query, data_to_insert)
        conn.commit()
        print(f"   âœ… {config['name']} å¤„ç†å®Œæˆï¼")

    conn.close()

if __name__ == "__main__":
    sync_data_to_pgvector()