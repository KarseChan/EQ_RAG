import os
from langchain_community.chat_models import ChatTongyi
from langchain.agents import create_agent

# è‡ªå®šä¹‰æ¨¡å—
from config import GRAPH_NAME
from tools import execute_cypher_query

# --- 1. åˆå§‹åŒ–æ¨¡å‹ ---
llm = ChatTongyi(model_name="qwen-max", temperature=0)

# --- 2. å‡†å¤‡å·¥å…· ---
tools = [execute_cypher_query]

# --- 3. å®šä¹‰ Prompt ---
system_prompt = f"""
ä½ æ˜¯ä¸€ä¸ª Apache AGE å›¾æ•°æ®åº“ä¸“å®¶ã€‚
å›¾è°± Schema: å›¾åç§° {GRAPH_NAME}ï¼ŒèŠ‚ç‚¹æ ‡ç­¾ :æ ¸æŸ¥äºº, :é˜²å¾¡åŒº, :æ‰¿è½½ä½“ï¼Œå…³ç³» :éš¶å±ã€‚

ã€æ ¸å¿ƒè§„åˆ™ã€‘
1. åªç”Ÿæˆ MATCH/RETURN è¯­å¥ï¼Œä¸¥ç¦ç”Ÿæˆ SQLã€‚
2. å¿…é¡»å°†è¿”å›å­—æ®µå°è£…åœ¨ Map ä¸­ï¼šRETURN {{info: n}}ã€‚
"""

# --- 4. åˆ›å»º Agent (LangGraphç‰ˆ) ---
agent = create_agent(
    model=llm,
    tools=tools,
    system_prompt=system_prompt
)

# --- 5. è¿è¡Œ ---
if __name__ == "__main__":
    print("ğŸš€ Agent (LangGraphç‰ˆ) å¯åŠ¨ä¸­...")

    # æµ‹è¯•é—®é¢˜
    user_question = "æœ‰å“ªäº›é˜²å¾¡åŒºæ‰¿è½½ä½“å…³ç³»ï¼Ÿ"
    
    # æ ¹æ®æ–‡æ¡£ï¼Œinvoke æ¥æ”¶ messages åˆ—è¡¨
    # æ ¼å¼: {"messages": [{"role": "user", "content": "..."}]}
    
    input_data = {
        "messages": [
            {"role": "user", "content": user_question}
        ]
    }
    
    print(f"\n-----------------\nç”¨æˆ·æé—®: {input_data['messages'][0]['content']}")
    
    try:
        # result åŒ…å«å®Œæ•´çš„çŠ¶æ€ï¼Œæˆ‘ä»¬éœ€è¦æå–æœ€åä¸€æ¡ AI å›å¤
        result = agent.invoke(input_data)
        
        # æ‰“å°æœ€ç»ˆå›å¤
        last_message = result['messages'][-1]
        print("\n=== æœ€ç»ˆç­”æ¡ˆ ===")
        print(last_message.content)

    except Exception as e:
        print(f"\nâŒ è¿è¡Œå‡ºé”™: {e}")