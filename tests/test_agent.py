import os
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from langchain_community.chat_models import ChatTongyi
from langchain.agents import create_agent

# è‡ªå®šä¹‰æ¨¡å—
from config import GRAPH_NAME
from tools import execute_cypher_query
from prompts import get_system_prompt

# --- 1. åˆå§‹åŒ–æ¨¡å‹ ---
llm = ChatTongyi(model_name="qwen-max", temperature=0)

# --- 2. å‡†å¤‡å·¥å…· ---
tools = [execute_cypher_query]

# --- 3. å®šä¹‰ Prompt ---
system_prompt = get_system_prompt()

# --- 4. åˆ›å»º Agent (LangGraphç‰ˆ) ---
agent = create_agent(
    model=llm,
    tools=tools,
    system_prompt=system_prompt
)

# --- 5. è¿è¡Œ ---
if __name__ == "__main__":
    print("ğŸš€ Agent (LangGraphç‰ˆ) å¯åŠ¨ä¸­...")

    # æµ‹è¯•é—®é¢˜
    user_question = "441323103033546é˜²å¾¡åŒºæ˜¯è°æ ¸æŸ¥çš„ï¼Ÿ"
    # user_question = "idä¸º441323103033546çš„é˜²å¾¡åŒºæœ‰å“ªäº›æ‰¿ç¾ä½“ï¼Ÿ"
    # user_question = "æœ±ç‚³æ¹–è´Ÿè´£å“ªäº›é˜²å¾¡åŒºï¼Ÿ"
    
    # æ ¹æ®æ–‡æ¡£ï¼Œinvoke æ¥æ”¶ messages åˆ—è¡¨
    # æ ¼å¼: {"messages": [{"role": "user", "content": "..."}]}
    
    input_data = {
        "messages": [
            {"role": "user", "content": user_question}
        ]
    }
    
    print(f"\n-----------------\nç”¨æˆ·æé—®: {input_data['messages'][0]['content']}")
    
    try:
        # result åŒ…å«å®Œæ•´çš„çŠ¶æ€ï¼Œæˆ‘ä»¬éœ€è¦æå–æœ€åä¸€æ¡ AI å›å¤
        result = agent.invoke(input_data)
        
        # æ‰“å°æœ€ç»ˆå›å¤
        last_message = result['messages'][-1]
        print("\n=== æœ€ç»ˆç­”æ¡ˆ ===")
        print(last_message.content)

    except Exception as e:
        print(f"\nâŒ è¿è¡Œå‡ºé”™: {e}")